{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67398e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/bergerar/BC-MRI-ADHD/Code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a255c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/bergerar/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from make_models import get_MRI_CVAE_3D\n",
    "from tqdm import tqdm \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db46943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'controls', 'patients']\n",
      "(440, 64, 64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179, 64, 64, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff = np.load('../Assets/brain_array-440.npz')\n",
    "print(list(stuff.keys()))\n",
    "\n",
    "data = stuff['data']\n",
    "control = stuff['controls']\n",
    "patients = stuff['patients']\n",
    "n = data.shape[0]\n",
    "print(data.shape)\n",
    "data[patients,:,:,:].shape\n",
    "data[patients].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e0cb92c-b838-4d7c-89ce-0ed79f8a313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "class cvae_data_loader_adhd():\n",
    "    ''' this is the info'''\n",
    "    def __init__(self,data,patients,batch_size=32):\n",
    "    \n",
    "        self.data = data\n",
    "        \n",
    "        self.n = data.shape[0]\n",
    "        self.epoch = -1\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.new_epoch()\n",
    "        self.n_batches = int(np.floor(min((len(self.adhd_idxs),len(self.td_idxs)))/self.batch_size)) # How many batches fit, take the min(n_ADHD,n_TD) then divide by batch size\n",
    "        \n",
    "    def new_epoch(self):\n",
    "\n",
    "        self.adhd_idxs = np.nonzero(patients==True)[0] # idxs of patients\n",
    "        self.td_idxs = np.nonzero(patients==False)[0] # idxs of TDs\n",
    "        \n",
    "        self.adhd_idxs = np.random.permutation(self.adhd_idxs)\n",
    "        self.td_idxs = np.random.permutation(self.td_idxs)\n",
    "        \n",
    "        self.epoch += 1\n",
    "        self.b = 0\n",
    "        \n",
    "        \n",
    "    def get_batch(self):\n",
    "        self.b += 1\n",
    "        \n",
    "        if self.b==self.n_batches:\n",
    "            self.new_epoch()\n",
    "        \n",
    "        self.batch_adhd_idx = self.adhd_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        self.batch_td_idx = self.td_idxs[np.arange(self.b*self.batch_size,self.b*self.batch_size+self.batch_size)]\n",
    "        # go through the patients and controls in batch size chunks\n",
    "        # batch_indeces = all_indices[batch number * batch size : batch number * batch size + batch size]\n",
    "        \n",
    "        self.batch_adhd = self.data[self.batch_adhd_idx,:,:,:]\n",
    "        self.batch_td = self.data[self.batch_td_idx,:,:,:]\n",
    "        \n",
    "        _,counts = np.unique(np.hstack((self.batch_adhd_idx,self.batch_td_idx)),return_counts=True)\n",
    "        assert all(counts==1),'not all unique, somethings wrong'\n",
    "        \n",
    "        return self.batch_adhd,self.batch_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69535bc-5fe4-4803-901c-85dceaeecee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = cvae_data_loader_adhd(data,patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641f7e85-dec8-4caa-8441-16625ed4cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f623bc3-b141-422a-9e05-f56863bb14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5806ecab-a43c-4e1d-ab61-60a3701d552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae, z_encoder, s_encoder, cvae_decoder = get_MRI_CVAE_3D(input_shape=(64,64,64,1),\n",
    "                    latent_dim=2,\n",
    "                    beta=1,\n",
    "                    disentangle=False,\n",
    "                    gamma=1,\n",
    "                    bias=True,\n",
    "                    batch_size = 64,\n",
    "                    kernel_size = 3,\n",
    "                    filters = 32,\n",
    "                    intermediate_dim = 128,\n",
    "                    opt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8016e12-2cb4-4e20-afee-c1e4ac60112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batches):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmod(epoch, \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m         \u001b[43mcvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mmfs1/data/bergerar/tf_weights_100_AB/cvae_weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     10\u001b[0m     adhd_batch, td_batch \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mget_batch()\n\u001b[1;32m     11\u001b[0m     l \u001b[38;5;241m=\u001b[39m cvae\u001b[38;5;241m.\u001b[39mtrain_on_batch([adhd_batch,td_batch])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2101\u001b[0m, in \u001b[0;36mModel.save_weights\u001b[0;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (optimizer\n\u001b[1;32m   2093\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(optimizer, trackable\u001b[38;5;241m.\u001b[39mTrackable)):\n\u001b[1;32m   2094\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   2095\u001b[0m       (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model was compiled with a Keras optimizer (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) but is being \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2096\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved in TensorFlow format with `save_weights`. The model\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2099\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConsider using a TensorFlow optimizer from `tf.train`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2100\u001b[0m       \u001b[38;5;241m%\u001b[39m (optimizer,))\n\u001b[0;32m-> 2101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trackable_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;66;03m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m checkpoint_management\u001b[38;5;241m.\u001b[39mupdate_checkpoint_state_internal(\n\u001b[1;32m   2104\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(filepath),\n\u001b[1;32m   2105\u001b[0m     model_checkpoint_path\u001b[38;5;241m=\u001b[39mfilepath,\n\u001b[1;32m   2106\u001b[0m     save_relative_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2107\u001b[0m     all_model_checkpoint_paths\u001b[38;5;241m=\u001b[39m[filepath])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1199\u001b[0m, in \u001b[0;36mTrackableSaver.save\u001b[0;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[1;32m   1196\u001b[0m   object_graph_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m file_io\u001b[38;5;241m.\u001b[39mrecursive_create_dir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(file_prefix))\n\u001b[0;32m-> 1199\u001b[0m save_path, new_feed_additions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_cached_when_graph_building\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_prefix_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_graph_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_feed_additions:\n\u001b[1;32m   1202\u001b[0m   feed_dict\u001b[38;5;241m.\u001b[39mupdate(new_feed_additions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1145\u001b[0m, in \u001b[0;36mTrackableSaver._save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_save_object_graph \u001b[38;5;241m!=\u001b[39m graph_proto\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;66;03m# When executing eagerly, we need to re-create SaveableObjects each time\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;66;03m# save() is called so they pick up new Tensors passed to their\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;66;03m# constructors. That means the Saver needs to be copied with a new\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;66;03m# var_list.\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function()):\n\u001b[1;32m   1144\u001b[0m   saver \u001b[38;5;241m=\u001b[39m functional_saver\u001b[38;5;241m.\u001b[39mMultiDeviceSaver(named_saveable_objects)\n\u001b[0;32m-> 1145\u001b[0m   save_op \u001b[38;5;241m=\u001b[39m \u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([save_op]):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/saving/functional_saver.py:295\u001b[0m, in \u001b[0;36mMultiDeviceSaver.save\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    293\u001b[0m   tf_function_save()\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msave_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/saving/functional_saver.py:269\u001b[0m, in \u001b[0;36mMultiDeviceSaver.save.<locals>.save_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m   sharded_prefixes\u001b[38;5;241m.\u001b[39mappend(shard_prefix)\n\u001b[1;32m    265\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# _SingleDeviceSaver will use the CPU device when necessary, but\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# initial read operations should be placed on the SaveableObject's\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# device.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     sharded_saves\u001b[38;5;241m.\u001b[39mappend(\u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(sharded_saves):\n\u001b[1;32m    272\u001b[0m   \u001b[38;5;66;03m# Merge on the io_device if specified, otherwise co-locates the merge op\u001b[39;00m\n\u001b[1;32m    273\u001b[0m   \u001b[38;5;66;03m# with the last device used.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m   merge_device \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    275\u001b[0m       options\u001b[38;5;241m.\u001b[39mexperimental_io_device \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    276\u001b[0m       saveable_object_util\u001b[38;5;241m.\u001b[39mset_cpu0(last_device))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/saving/functional_saver.py:74\u001b[0m, in \u001b[0;36m_SingleDeviceSaver.save\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m saveable\u001b[38;5;241m.\u001b[39mspecs:\n\u001b[1;32m     73\u001b[0m     tensor_names\u001b[38;5;241m.\u001b[39mappend(spec\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m---> 74\u001b[0m     tensors\u001b[38;5;241m.\u001b[39mappend(\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m)\n\u001b[1;32m     75\u001b[0m     tensor_slices\u001b[38;5;241m.\u001b[39mappend(spec\u001b[38;5;241m.\u001b[39mslice_spec)\n\u001b[1;32m     76\u001b[0m save_device \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mexperimental_io_device \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/saving/saveable_object.py:55\u001b[0m, in \u001b[0;36mSaveSpec.tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/saving/saveable_object_util.py:106\u001b[0m, in \u001b[0;36mResourceVariableSaveable.__init__.<locals>._read_variable_closure.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# To allow variables placed on non-CPU devices to be checkpointed,\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# we copy them to CPU on the same machine first.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/device:CPU:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 106\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:287\u001b[0m, in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    284\u001b[0m   \u001b[38;5;66;03m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[1;32m    285\u001b[0m   \u001b[38;5;66;03m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m   \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 287\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_handle_data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:3987\u001b[0m, in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3986\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3987\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3988\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3989\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_callbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3991\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make sure you have GPU enabled\n",
    "\n",
    "n_epochs = 100\n",
    "n_batches = data_loader.n_batches # dataloader calcs how many batches\n",
    "loss = []\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for batch in range(n_batches):\n",
    "        if np.mod(epoch, 10) == 0:\n",
    "            cvae.save_weights('/mmfs1/data/bergerar/tf_weights_100_AB/cvae_weights') \n",
    "        adhd_batch, td_batch = data_loader.get_batch()\n",
    "        l = cvae.train_on_batch([adhd_batch,td_batch])\n",
    "        loss.append(l)\n",
    "        if np.mod(epoch, 10) == 0:\n",
    "            np.save('loss_100_epochs_AB', np.array(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b44e9-9c41-4982-8cb3-eea34dfbe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#epoch = 100\n",
    "#if np.mod(epoch, 100) == 0:\n",
    "   # cvae.save_weights('/mmfs1/data/bergerar/tf_weightsAB/cvae_weights') \n",
    "   # print(\"save weights\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f26a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvae.predict([adhd_batch,td_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd73d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(adhd_batch[0,:,:,32])\n",
    "plt.title('input')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(predictions[0][0,:,:,32,0])\n",
    "plt.title('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83561204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_loss = cvae.train_on_batch([adhd_batch,td_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25375919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "#cvae.save_weights('/mmfs1/data/bergerar/tf_weightsAB/cvae_weights') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb654a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rsa_funcs import fit_rsa,make_RDM,get_triu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba03e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symptoms = np.random.rand(100)\n",
    "# latent_shared = np.random.rand(100)\n",
    "# latent_specific = np.random.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symptom_similarity = make_RDM(symptoms)\n",
    "# shared_similarity = make_RDM(latent_shared)\n",
    "# specific_similarity  = make_RDM(latent_specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(symptom_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a08dd-e12b-4b34-a1bc-f26d1ecc40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_rsa(symptom_similarity,shared_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33ad7e-1ee3-4e39-82dc-a71c7da1adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_rsa(symptom_similarity,specific_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
