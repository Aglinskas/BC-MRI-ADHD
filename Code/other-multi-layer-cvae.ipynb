{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d9dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec95aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MRI_CCVAE_3D(input_shape=(64,64,64,1), latent_dim=2, beta=1, disentangle=False, gamma=1, bias=True, batch_size = 64):\n",
    "\n",
    "    image_size, _, _, channels = input_shape\n",
    "    kernel_size = 3\n",
    "    filters = 32\n",
    "    intermediate_dim = 128\n",
    "    epochs = 10\n",
    "    nlayers = 2\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "\n",
    "    z_conv1 = Conv3D(filters=filters*2,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "    z_conv2 = Conv3D(filters=filters*4,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    z_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    z_mean_layer = Dense(latent_dim, name='z_mean', use_bias=bias)\n",
    "    z_log_var_layer = Dense(latent_dim, name='z_log_var', use_bias=bias)\n",
    "    z_layer = Lambda(sampling, output_shape=(latent_dim,), name='z')\n",
    "\n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "        z_h = z_conv1(z_h)\n",
    "        z_h = z_conv2(z_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "\n",
    "\n",
    "    s_conv1 = Conv3D(filters=filters*2,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "    s_conv2 = Conv3D(filters=filters*4,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    s_mean_layer = Dense(latent_dim, name='s_mean', use_bias=bias)\n",
    "    s_log_var_layer = Dense(latent_dim, name='s_log_var', use_bias=bias)\n",
    "    s_layer = Lambda(sampling, output_shape=(latent_dim,), name='s')\n",
    "\n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "        s_h = s_conv1(s_h)\n",
    "        s_h = s_conv2(s_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        s_log_var =  s_log_var_layer(s_h)\n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    #bg_s_mean, bg_s_log_var, bg_s, _ = s_encoder_func(bg_inputs) # this is what they had \n",
    "    bg_z_mean, bg_z_log_var, bg_z, _ = z_encoder_func(bg_inputs) # Aidas and Stefano team hax\n",
    "\n",
    "\n",
    "      # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "\n",
    "      # build decoder model\n",
    "    latent_inputs = Input(shape=(2*latent_dim,), name='z_sampling')\n",
    "\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3] * shape_z[4], activation='relu', use_bias=bias)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3],shape_z[4]))(x)\n",
    "\n",
    "    for i in range(nlayers):\n",
    "        x = Conv3DTranspose(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=2,\n",
    "                          use_bias=bias,\n",
    "                          padding='same')(x)\n",
    "        filters //= 2\n",
    "\n",
    "    outputs = Conv3DTranspose(filters=1,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            use_bias=bias,\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "      # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_z)\n",
    "\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([bg_z, zeros], -1)) # Aidas look into this, is this correct\n",
    "\n",
    " #   fg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, zeros], -1))\n",
    "\n",
    "    # instantiate VAE model\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                              outputs=[tg_outputs, bg_outputs], \n",
    "                              name='contrastive_vae')\n",
    "\n",
    "#     cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "#                                   outputs=fg_outputs, \n",
    "#                                   name='contrastive_vae_fg')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs), K.flatten(tg_outputs)) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs), K.flatten(bg_outputs)) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]\n",
    "\n",
    "\n",
    "    kl_loss = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss += 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss += 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "    kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    \n",
    "    #print(f'reconstruction loss {reconstruction_loss}')\n",
    "    #print(f'kl_loss loss {kl_loss}')\n",
    "    #print(f'tc_loss loss {tc_loss}')\n",
    "    #print(f'discriminator_loss loss {discriminator_loss}')\n",
    "    \n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma*tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "    \n",
    "#     opt = tf.keras.optimizers.SGD(\n",
    "#     learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD')\n",
    "\n",
    "    #opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "    \n",
    "    #cvae.compile(optimizer='rmsprop',run_eagerly=True)\n",
    "    cvae.compile(optimizer=opt,run_eagerly=True)\n",
    "    \n",
    "\n",
    "    #return cvae, cvae_fg, z_encoder, s_encoder, cvae_decoder\n",
    "    return cvae, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fe6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
