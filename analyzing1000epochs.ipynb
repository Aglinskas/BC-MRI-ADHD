{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79394491-0443-4a2b-8044-00212fbe4888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "      args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "      z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def get_MRI_VAE_3D(input_shape=(64,64,64,1),\n",
    "                   latent_dim=2,\n",
    "                   batch_size = 32,\n",
    "                   disentangle=False,\n",
    "                   gamma=1,\n",
    "                   kernel_size = 3,\n",
    "                   filters = 16,\n",
    "                   intermediate_dim = 128,\n",
    "                   opt=None):\n",
    "    #TODO: add discriminator loss, see if there is improvement. Perhaps try on shapes dataset if it's easier...\n",
    "\n",
    "    image_size, _, _, channels = input_shape\n",
    "    \n",
    "    #epochs = 10\n",
    "    nlayers = 2\n",
    "      \n",
    "      # VAE model = encoder + decoder\n",
    "      # build encoder model\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = inputs\n",
    "    for i in range(nlayers):\n",
    "        filters *= 2\n",
    "        x = Conv3D(filters=filters,\n",
    "                kernel_size=kernel_size,\n",
    "                activation='relu',\n",
    "                strides=2,\n",
    "                padding='same')(x)\n",
    "\n",
    "    # shape info needed to build decoder model\n",
    "    shape = K.int_shape(x)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(intermediate_dim, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    # instantiate encoder model\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "    # build decoder model\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    x = Dense(shape[1] * shape[2] * shape[3] * shape[4], activation='relu')(x)\n",
    "    x = Reshape((shape[1], shape[2], shape[3],shape[4]))(x)\n",
    "\n",
    "    for i in range(nlayers):\n",
    "        x = Conv3DTranspose(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=2,\n",
    "                          padding='same')(x)\n",
    "        filters //= 2\n",
    "\n",
    "    outputs = Conv3DTranspose(filters=1,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    #     decoder.summary()\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:int(latent_dim/2)])(z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:int(latent_dim/2)])(z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),int(latent_dim/2):])(z)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,int(latent_dim/2):])(z)\n",
    "        \n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "        \n",
    "#         q_bar_score = discriminator(q_bar)\n",
    "#         q_score = discriminator(q)        \n",
    "#         tc_loss = K.log(q_score / (1 - q_score)) \n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "\n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "\n",
    "    reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "    reconstruction_loss *= image_size * image_size\n",
    "\n",
    "\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    if disentangle:\n",
    "        vae_loss = K.mean(reconstruction_loss) + K.mean(kl_loss) + gamma * K.mean(tc_loss) + K.mean(discriminator_loss)\n",
    "    else:\n",
    "        vae_loss = K.mean(reconstruction_loss) + K.mean(kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    \n",
    "    if type(opt)==type(None):\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "        \n",
    "    #vae.compile(optimizer='rmsprop')\n",
    "    vae.compile(optimizer=opt)\n",
    "    \n",
    "\n",
    "    if disentangle:\n",
    "        vae.metrics_tensors = [reconstruction_loss, kl_loss, tc_loss, discriminator_loss]\n",
    "        #     vae.summary()\n",
    "    return encoder, decoder, vae\n",
    "\n",
    "\n",
    "\n",
    "def get_MRI_CVAE_3D(input_shape=(64,64,64,1),\n",
    "                    latent_dim=2,\n",
    "                    beta=1,\n",
    "                    disentangle=False,\n",
    "                    gamma=1,\n",
    "                    bias=True,\n",
    "                    batch_size = 64,\n",
    "                    kernel_size = 3,\n",
    "                    filters = 32,\n",
    "                    intermediate_dim = 128,\n",
    "                    opt=None):\n",
    "\n",
    "    image_size, _, _, channels = input_shape\n",
    "    #epochs = 10\n",
    "    nlayers = 2\n",
    "\n",
    "    # build encoder model\n",
    "    tg_inputs = Input(shape=input_shape, name='tg_inputs')\n",
    "    bg_inputs = Input(shape=input_shape, name='bg_inputs')\n",
    "\n",
    "    z_conv1 = Conv3D(filters=filters*2,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "    z_conv2 = Conv3D(filters=filters*4,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    z_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    z_mean_layer = Dense(latent_dim, name='z_mean', use_bias=bias)\n",
    "    z_log_var_layer = Dense(latent_dim, name='z_log_var', use_bias=bias)\n",
    "    z_layer = Lambda(sampling, output_shape=(latent_dim,), name='z')\n",
    "\n",
    "    def z_encoder_func(inputs):\n",
    "        z_h = inputs\n",
    "        z_h = z_conv1(z_h)\n",
    "        z_h = z_conv2(z_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(z_h)\n",
    "        z_h = Flatten()(z_h)\n",
    "        z_h = z_h_layer(z_h)\n",
    "        z_mean =  z_mean_layer(z_h)\n",
    "        z_log_var =  z_log_var_layer(z_h)\n",
    "        z = z_layer([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z, shape\n",
    "\n",
    "    tg_z_mean, tg_z_log_var, tg_z, shape_z = z_encoder_func(tg_inputs)\n",
    "\n",
    "\n",
    "    s_conv1 = Conv3D(filters=filters*2,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "    s_conv2 = Conv3D(filters=filters*4,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            strides=2,\n",
    "            use_bias=bias,\n",
    "            padding='same')\n",
    "\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    s_h_layer = Dense(intermediate_dim, activation='relu', use_bias=bias)\n",
    "    s_mean_layer = Dense(latent_dim, name='s_mean', use_bias=bias)\n",
    "    s_log_var_layer = Dense(latent_dim, name='s_log_var', use_bias=bias)\n",
    "    s_layer = Lambda(sampling, output_shape=(latent_dim,), name='s')\n",
    "\n",
    "    def s_encoder_func(inputs):\n",
    "        s_h = inputs\n",
    "        s_h = s_conv1(s_h)\n",
    "        s_h = s_conv2(s_h)\n",
    "        # shape info needed to build decoder model\n",
    "        shape = K.int_shape(s_h)\n",
    "        s_h = Flatten()(s_h)\n",
    "        s_h = s_h_layer(s_h)\n",
    "        s_mean =  s_mean_layer(s_h)\n",
    "        s_log_var =  s_log_var_layer(s_h)\n",
    "        s = s_layer([s_mean, s_log_var])\n",
    "        return s_mean, s_log_var, s, shape\n",
    "\n",
    "    tg_s_mean, tg_s_log_var, tg_s, shape_s = s_encoder_func(tg_inputs)\n",
    "    #bg_s_mean, bg_s_log_var, bg_s, _ = s_encoder_func(bg_inputs) # this is what they had \n",
    "    bg_z_mean, bg_z_log_var, bg_z, _ = z_encoder_func(bg_inputs) # Aidas and Stefano team hax\n",
    "\n",
    "\n",
    "      # instantiate encoder models\n",
    "    z_encoder = tf.keras.models.Model(tg_inputs, [tg_z_mean, tg_z_log_var, tg_z], name='z_encoder')\n",
    "    s_encoder = tf.keras.models.Model(tg_inputs, [tg_s_mean, tg_s_log_var, tg_s], name='s_encoder')\n",
    "\n",
    "\n",
    "      # build decoder model\n",
    "    latent_inputs = Input(shape=(2*latent_dim,), name='z_sampling')\n",
    "\n",
    "    x = Dense(intermediate_dim, activation='relu', use_bias=bias)(latent_inputs)\n",
    "    x = Dense(shape_z[1] * shape_z[2] * shape_z[3] * shape_z[4], activation='relu', use_bias=bias)(x)\n",
    "    x = Reshape((shape_z[1], shape_z[2], shape_z[3],shape_z[4]))(x)\n",
    "\n",
    "    for i in range(nlayers):\n",
    "        x = Conv3DTranspose(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='relu',\n",
    "                          strides=2,\n",
    "                          use_bias=bias,\n",
    "                          padding='same')(x)\n",
    "        filters //= 2\n",
    "\n",
    "    outputs = Conv3DTranspose(filters=1,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='sigmoid',\n",
    "                            padding='same',\n",
    "                            use_bias=bias,\n",
    "                            name='decoder_output')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    cvae_decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "      # decoder.summary()\n",
    "\n",
    "    def zeros_like(x):\n",
    "        return tf.zeros_like(x)\n",
    "\n",
    "    tg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, tg_s], -1))\n",
    "    zeros = tf.keras.layers.Lambda(zeros_like)(tg_z)\n",
    "\n",
    "    bg_outputs = cvae_decoder(tf.keras.layers.concatenate([bg_z, zeros], -1)) # Aidas look into this, is this correct\n",
    "\n",
    " #   fg_outputs = cvae_decoder(tf.keras.layers.concatenate([tg_z, zeros], -1))\n",
    "\n",
    "    # instantiate VAE model\n",
    "    cvae = tf.keras.models.Model(inputs=[tg_inputs, bg_inputs], \n",
    "                              outputs=[tg_outputs, bg_outputs], \n",
    "                              name='contrastive_vae')\n",
    "\n",
    "#     cvae_fg = tf.keras.models.Model(inputs=tg_inputs, \n",
    "#                                   outputs=fg_outputs, \n",
    "#                                   name='contrastive_vae_fg')\n",
    "\n",
    "    if disentangle:\n",
    "        discriminator = Dense(1, activation='sigmoid')\n",
    "\n",
    "        z1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_z)\n",
    "        z2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_z)\n",
    "        s1 = Lambda(lambda x: x[:int(batch_size/2),:])(tg_s)\n",
    "        s2 = Lambda(lambda x: x[int(batch_size/2):,:])(tg_s)\n",
    "\n",
    "        q_bar = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z2], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z1], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q = tf.keras.layers.concatenate(\n",
    "          [tf.keras.layers.concatenate([s1, z1], axis=1),\n",
    "          tf.keras.layers.concatenate([s2, z2], axis=1)],\n",
    "          axis=0)\n",
    "\n",
    "        q_bar_score = (discriminator(q_bar)+.1) *.85 # +.1 * .85 so that it's 0<x<1\n",
    "        q_score = (discriminator(q)+.1) *.85 \n",
    "        tc_loss = K.log(q_score / (1 - q_score)) \n",
    "        discriminator_loss = - K.log(q_score) - K.log(1 - q_bar_score)\n",
    "    else:\n",
    "        tc_loss = 0\n",
    "        discriminator_loss = 0\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.mse(K.flatten(tg_inputs), K.flatten(tg_outputs)) \n",
    "    reconstruction_loss += tf.keras.losses.mse(K.flatten(bg_inputs), K.flatten(bg_outputs)) \n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2] * input_shape[3]\n",
    "\n",
    "\n",
    "    kl_loss = 1 + tg_z_log_var - tf.keras.backend.square(tg_z_mean) - tf.keras.backend.exp(tg_z_log_var)\n",
    "    kl_loss += 1 + tg_s_log_var - tf.keras.backend.square(tg_s_mean) - tf.keras.backend.exp(tg_s_log_var)\n",
    "    kl_loss += 1 + bg_z_log_var - tf.keras.backend.square(bg_z_mean) - tf.keras.backend.exp(bg_z_log_var)\n",
    "    kl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    \n",
    "    \n",
    "    #print(f'reconstruction loss {reconstruction_loss}')\n",
    "    #print(f'kl_loss loss {kl_loss}')\n",
    "    #print(f'tc_loss loss {tc_loss}')\n",
    "    #print(f'discriminator_loss loss {discriminator_loss}')\n",
    "    \n",
    "    cvae_loss = tf.keras.backend.mean(reconstruction_loss + beta*kl_loss + gamma*tc_loss + discriminator_loss)\n",
    "    cvae.add_loss(cvae_loss)\n",
    "    \n",
    "    if type(opt)==type(None):\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam')\n",
    "    \n",
    "#     opt = tf.keras.optimizers.SGD(\n",
    "#     learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD')\n",
    "\n",
    "    #opt = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.9, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "    \n",
    "    #cvae.compile(optimizer='rmsprop',run_eagerly=True)\n",
    "    cvae.compile(optimizer=opt,run_eagerly=True)\n",
    "    \n",
    "\n",
    "    #return cvae, cvae_fg, z_encoder, s_encoder, cvae_decoder\n",
    "    return cvae, z_encoder, s_encoder, cvae_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9e1bc8-d3f1-4996-b950-a1fc3478bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9a89bb-737f-4ab8-8305-7da2236710b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/bergerar/BC-MRI-ADHD'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fead0e5f-d999-4a11-8c5a-cb165cc73c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae, z_encoder, s_encoder, cvae_decoder = get_MRI_CVAE_3D(input_shape=(64,64,64,1),\n",
    "                    latent_dim=2,\n",
    "                    beta=1,\n",
    "                    disentangle=False,\n",
    "                    gamma=1,\n",
    "                    bias=True,\n",
    "                    batch_size = 64,\n",
    "                    kernel_size = 3,\n",
    "                    filters = 32,\n",
    "                    intermediate_dim = 128,\n",
    "                    opt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b90d66f8-3951-4c55-82c2-a24c65d50d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/data/bergerar/BC-MRI-ADHD/Assets\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "099aa7a8-bb72-439a-9f15-5f18e887c324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/data/bergerar/BC-MRI-ADHD\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2836dc21-04bd-401d-b494-96d934ae53cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/data/bergerar\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbfed3f3-469c-4b3e-9756-59bda8a3b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/data/bergerar/BC-MRI-ADHD\n"
     ]
    }
   ],
   "source": [
    "cd BC-MRI-ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "755e1649-e25c-486c-aaa4-adee3493b842",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mmfs1/data/bergerar/BC-MRI-ADHD/Assets/tf_weights_10000_AB/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py:95\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mmfs1/data/bergerar/BC-MRI-ADHD/Assets/tf_weights_10000_AB/",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m load_weights \u001b[38;5;241m=\u001b[39m \u001b[43mcvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mmfs1/data/bergerar/BC-MRI-ADHD/Assets/tf_weights_10000_AB/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2176\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2175\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2176\u001b[0m     \u001b[43mpy_checkpoint_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNewCheckpointReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2177\u001b[0m     save_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2178\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mDataLossError:\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;66;03m# The checkpoint is not readable in TensorFlow format. Try HDF5.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py:99\u001b[0m, in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# issue with throwing python exceptions from C++.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 99\u001b[0m   \u001b[43merror_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py:35\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     31\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[0;32m---> 35\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mUnimplementedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mmfs1/data/bergerar/BC-MRI-ADHD/Assets/tf_weights_10000_AB/"
     ]
    }
   ],
   "source": [
    "load_weights = cvae.load_weights(\"/mmfs1/data/bergerar/BC-MRI-ADHD/Assets/tf_weights_10000_AB/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d9c0f68-e161-4b62-8d0b-0c544eb1b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb54780e-cee8-48a4-9ca5-6a38bd1b540f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/data/bergerar/BC-MRI-ADHD'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2a13c-da01-4d9d-8e96-575c3e34e5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3408791d-888a-42ef-b0ea-31c8c300a315",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m stuff_in \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mmfs1/data/bergerar/BC-MRI-ADHD/Assets/brain_array-440.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m stuff_out \u001b[38;5;241m=\u001b[39m \u001b[43mload_weights\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_weights' is not defined"
     ]
    }
   ],
   "source": [
    "stuff_in = np.load('/mmfs1/data/bergerar/BC-MRI-ADHD/Assets/brain_array-440.npz')\n",
    "stuff_out = load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97db4944-ca63-4a85-8417-7dadf48542c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stuff_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m MSE \u001b[38;5;241m=\u001b[39m ((stuff_in \u001b[38;5;241m-\u001b[39m \u001b[43mstuff_out\u001b[49m)\u001b[38;5;241m^\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m440\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stuff_out' is not defined"
     ]
    }
   ],
   "source": [
    "MSE = ((stuff_in - stuff_out)^2) / 440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2939bc8-b17e-427f-b40e-64f57c76c52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4cfac-0b53-4298-b07f-7aa0319dbae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f81365-554f-4721-ba76-4e7537429d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d267e19-95f9-4b40-91a4-7491b8bb0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/data/bergerar/BC-MRI-ADHD/Assets/tf_weights_10000_AB\n"
     ]
    }
   ],
   "source": [
    "cd ~/BC-MRI-ADHD/Assets/tf_weights_10000_AB/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adbd9c7d-cec1-4775-bec4-7fb9b7404a15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_weights_10000_AB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cvae\u001b[38;5;241m.\u001b[39mload_weights(\u001b[43mtf_weights_10000_AB\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_weights_10000_AB' is not defined"
     ]
    }
   ],
   "source": [
    "#cvae.load_weights(tf_weights_10000_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e1a71-e20b-4c4c-a9dd-a1c900a0737b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50422632-bdae-4bf9-9da5-0d662b4857f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'loadweights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadweights\u001b[49m(tf_weights_10000_AB)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'loadweights'"
     ]
    }
   ],
   "source": [
    "#cvae.loadweights(tf_weights_10000_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0292ef-94ce-460b-a936-7d9bf4eb908b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700d27a-cf34-4073-ba3f-d3723618d89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7b444-db78-48a4-b65f-b866491b4f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665b244-eb57-476e-8471-78ee6aeb24ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
